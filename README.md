# Projet 9 chatbot ia RAG


## Lien github

https://github.com/Vagaboss/Projet-9-RAG 

.
## ğŸ¯ Objectif

Ce projet a pour objectif de dÃ©velopper un systÃ¨me RAG (Retrieval-Augmented Generation) permettant de rÃ©pondre en langage naturel Ã  des questions sur des Ã©vÃ©nements culturels et professionnels issus dâ€™OpenAgenda.
Lâ€™utilisateur peut poser une question comme : 

 "Quels concerts de musique classique en avril 2025 Ã  Paris ?".

Le systÃ¨me va alors :
- Rechercher les Ã©vÃ©nements pertinents dans une base vectorielle construite avec FAISS.


- GÃ©nÃ©rer une rÃ©ponse claire et contextualisÃ©e grÃ¢ce au modÃ¨le de langage Mistral.


- Fournir la rÃ©ponse via une API REST exposÃ©e avec FastAPI.

## ğŸ“‚ Structure du projet

api/main.py : API FastAPI avec les endpoints /ask, /rebuild et /health


rag/chatbot.py : ChaÃ®ne RAG qui combine FAISS + Mistral


rag/vector_pipe.py : PrÃ©traitement des donnÃ©es et construction de lâ€™index FAISS


scripts/build_index.py : Script pour reconstruire lâ€™index FAISS


eval/eval_data.json : Jeu de test avec questions et rÃ©ponses attendues


eval/evaluate_rag.py : Script dâ€™Ã©valuation avec Ragas


data/events_clean.json : DonnÃ©es sources nettoyÃ©es


requirements.txt : DÃ©pendances Python


Dockerfile : Conteneurisation de lâ€™API


README.md : PrÃ©sentation du projet



### ğŸ“¦ Installation
1. Cloner le projet

- git clone <https://github.com/Vagaboss/Projet-9-RAG.git>
- cd Projet-9-RAG

2. CrÃ©er un environnement virtuel

Selon ton terminal :

- PowerShell
python -m venv env
.\env\Scripts\Activate.ps1

- Invite de commandes (cmd.exe)
python -m venv env
.\env\Scripts\activate.bat

- Git Bash
python -m venv env
source env/Scripts/activate

âš ï¸ Le dossier env/ est ignorÃ© par Git (cf. .gitignore).

3. Installer les dÃ©pendances

4. DÃ©finir la clÃ© API Mistral
CrÃ©er un fichier .env Ã  la racine du projet et ajouter :
 MISTRAL_API_KEY=ta_clef_api (recupÃ©rÃ© sur le site de mistralai : prendre l'abonnement gratuit)

5. Construire lâ€™index FAISS
python scripts/build_index.py

6. Lancer lâ€™API FastAPI
uvicorn api.main:app --reload
Endpoints accessibles :
- Docs interactives : http://127.0.0.1:8000/docs
- Healthcheck : http://127.0.0.1:8000/health

7. Exemple dâ€™appel API :

POST /ask
{ "question": "Quels concerts de musique classique en avril 2025 Ã  Paris ?" }


## ğŸ³ ExÃ©cution avec Docker

1. Builder lâ€™image
docker build -t rag-api .
2. Lancer le conteneur
docker run -p 8000:8000 --env-file .env rag-api
3. AccÃ©der Ã  lâ€™API dans le docker
Swagger : http://127.0.0.1:8000/docs

## ğŸ“Š Ã‰valuation avec Ragas
Verifier que l'api est bien lancÃ©e
Lancer lâ€™Ã©valuation
python -m eval.evaluate_rag
Exemple de rÃ©sultats
Answer relevancy : 0.56


Faithfulness : 0.59


Context precision : 0.10


Context recall : 0.18


Ces rÃ©sultats montrent que le systÃ¨me est pertinent mais quâ€™il peut encore Ãªtre amÃ©liorÃ©, notamment sur la couverture contextuelle.



ğŸ“Š RÃ©sultats obtenus

Answer relevancy : 0.56
â†’ Dans un peu plus de la moitiÃ© des cas, la rÃ©ponse est jugÃ©e pertinente par rapport Ã  la question.
â†’ Câ€™est â€œmoyenâ€, mais logique pour un POC (on nâ€™a pas encore optimisÃ© le prompt, le retriever ou les embeddings).

Faithfulness : 0.59
â†’ La rÃ©ponse respecte le contexte fourni dans ~60% des cas.
â†’ En clair : le bot a tendance Ã  inventer ou extrapoler parfois.

Context precision : 0.10
â†’ Seulement 10% du contexte fourni est rÃ©ellement utilisÃ© pour gÃ©nÃ©rer la rÃ©ponse.
â†’ Ã‡a veut dire que ton retriever envoie beaucoup de â€œbruitâ€ (docs non pertinents).

Context recall : 0.18
â†’ Seulement 18% des infos pertinentes du contexte sont utilisÃ©es.
â†’ Donc soit le retriever ne trouve pas toujours les bons passages, soit le modÃ¨le ne les exploite pas bien.

## ğŸ‘¨â€ğŸ’» Auteur
Projet rÃ©alisÃ© dans le cadre de la formation Data Scientist â€“ OpenClassrooms.