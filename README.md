# Projet 9 chatbot ia RAG

### ğŸ¯ Objectif

Ce dÃ©pÃ´t contient le Proof of Concept dâ€™un chatbot RAG (Retrieval-Augmented Generation) pour recommander des Ã©vÃ©nements culturels Ã  partir de lâ€™API OpenAgenda, en utilisant LangChain, Mistral et Faiss.

Ce document dÃ©crit uniquement lâ€™installation de lâ€™environnement de dÃ©veloppement pour pouvoir exÃ©cuter les prochains scripts (ingestion, vectorisation, API).

### ğŸ› ï¸ PrÃ©requis

- Python â‰¥ 3.8 installÃ© sur la machine (testÃ© avec Python 3.13.3)

- Git installÃ©

- Une connexion Internet pour tÃ©lÃ©charger les dÃ©pendances

- SystÃ¨me : Windows (fonctionne aussi sous Linux/Mac avec adaptations mineures)

### ğŸ“¦ Installation
1. Cloner le projet

- git clone <url-du-repo>
- cd puls-events-rag

2. CrÃ©er un environnement virtuel

Selon ton terminal :

- PowerShell
python -m venv env
.\env\Scripts\Activate.ps1

- Invite de commandes (cmd.exe)
python -m venv env
.\env\Scripts\activate.bat

- Git Bash
python -m venv env
source env/Scripts/activate

âš ï¸ Le dossier env/ est ignorÃ© par Git (cf. .gitignore).

3. Installer les dÃ©pendances

- pip install -r requirements.txt

- Les principales bibliothÃ¨ques installÃ©es sont :

- faiss-cpu (vectorisation)

- langchain et langchain-community

- mistralai

- transformers, torch, sentence-transformers

- fastapi, uvicorn

- pytest, python-dotenv

4. VÃ©rifier que lâ€™environnement est bien activÃ©

which python
ou
python -c "import sys; print(sys.prefix)"

Le chemin doit pointer vers le dossier du projet, par ex. :
.../Projet 9 RAG/env

5. Tester les imports

- Dans le shell Python :

import faiss
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from mistralai.client import MistralClient

Si aucune erreur ne sâ€™affiche âœ… â†’ lâ€™environnement est prÃªt.



ğŸ“Š RÃ©sultats obtenus

Answer relevancy : 0.56
â†’ Dans un peu plus de la moitiÃ© des cas, la rÃ©ponse est jugÃ©e pertinente par rapport Ã  la question.
â†’ Câ€™est â€œmoyenâ€, mais logique pour un POC (on nâ€™a pas encore optimisÃ© le prompt, le retriever ou les embeddings).

Faithfulness : 0.59
â†’ La rÃ©ponse respecte le contexte fourni dans ~60% des cas.
â†’ En clair : le bot a tendance Ã  inventer ou extrapoler parfois.

Context precision : 0.10
â†’ Seulement 10% du contexte fourni est rÃ©ellement utilisÃ© pour gÃ©nÃ©rer la rÃ©ponse.
â†’ Ã‡a veut dire que ton retriever envoie beaucoup de â€œbruitâ€ (docs non pertinents).

Context recall : 0.18
â†’ Seulement 18% des infos pertinentes du contexte sont utilisÃ©es.
â†’ Donc soit le retriever ne trouve pas toujours les bons passages, soit le modÃ¨le ne les exploite pas bien.